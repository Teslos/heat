defaults:
  - modulus_default
  - scheduler: tf_exponential_lr
  - optimizer: adam
  - loss: sum
  - _self_

scheduler:
  decay_rate: 0.95
  decay_steps: 1000

training:
  rec_results_freq: 1000
  rec_constraint_freq: 1000
  max_steps: 100000

batch_size:
  heat_source: 100
  walls: 1000
